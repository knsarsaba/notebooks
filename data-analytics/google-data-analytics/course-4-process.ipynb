{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc11665-c8a6-41cb-8213-bc65d1a42642",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Process Data from Dirty to Clean\n",
    "\n",
    "Notes from this course: https://www.coursera.org/learn/process-data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f9abfc-f7be-4f9b-aca0-208d360bb640",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Module 1: The importance of integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8420e3-9dc2-42d0-924c-d991ff30de55",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Learning log\n",
    "\n",
    "#### Focus on integrity\n",
    "- A strong analysis depends on the integrity of the data\n",
    "\n",
    "#### Data integrity and analytics objectives\n",
    "- Data integrity\n",
    "    - The accuracy, completeness, consistency, and trustworthiness of data throughout its lifecycle\n",
    "- One missing piece can make all of your data useless\n",
    "- Ways data can be compromised\n",
    "    - Replicated\n",
    "        - There's a chance data data will be out of sync\n",
    "        - Example: One analyst copies a large dataset to check the dates. But because of memory issues, only part of the dataset is actually copied. The analyst would be verifying and standardizing incomplete data. That partial dataset would be certified as compliant but the full dataset would still contain dates that weren't verified. Two versions of a dataset can introduce inconsistent results. A final audit of results would be essential to reveal what happened and correct all dates\n",
    "    - Transferred\n",
    "        - Might end up with incomplete data if data transfer is interrupted\n",
    "        - Example: Another analyst checks the dates in a spreadsheet and chooses to import the validated and standardized data back to the database. But suppose the date field from the spreadsheet was incorrectly classified as a text field during the data import (transfer) process. Now some of the dates in the database are stored as text strings. At this point, the data needs to be cleaned to restore its integrity.\n",
    "    - Manipulated\n",
    "        - An error during the process can compromise the efficiency\n",
    "        - Example: When checking dates, another analyst notices what appears to be a duplicate record in the database and removes it. But it turns out that the analyst removed a unique record for a company’s subsidiary and not a duplicate record for the company. Your dataset is now missing data and the data must be restored for completeness.\n",
    "- Data replication\n",
    "    - Is the process of storing data in multiple locations\n",
    "- Data transfer\n",
    "    - The process of copying data from a storage device to memory, or from one computer to another\n",
    "- Data manipulation\n",
    "    - The process of changing data to make it more organized and easier to read\n",
    "- Other threats to data integrity\n",
    "    - Human error\n",
    "    - Viruses\n",
    "    - Malware\n",
    "    - Hacking\n",
    "    - System failures\n",
    "- Data constraints and examples\n",
    "    - Data type\n",
    "        - Values must be of a certain type: date, number, percentage, Boolean, etc\n",
    "        - Example: If the data type is a date, a single number like 30 would fail the constraint and be invalid\n",
    "    - Data range\n",
    "        - Values must fall between predefined maximum and minimum values\n",
    "        - Example: If the data range is 10-20, a value of 30 would fail the constraint and be invalid\n",
    "    - Mandatory\n",
    "        - Values can’t be left blank or empty\n",
    "        - Example: If age is mandatory, that value must be filled in\n",
    "    - Unique\n",
    "        - Values can’t have a duplicate\n",
    "        - Example: Two people can’t have the same mobile phone number within the same service area\n",
    "    - Regular expression (regex) patterns\n",
    "        - Values must match a prescribed pattern\n",
    "        - Example: A phone number must match ###-###-#### (no other characters allowed)\n",
    "    - Cross-field validation\n",
    "        - Certain conditions for multiple fields must be satisfied\n",
    "        - Example: Values are percentages and values from multiple fields must add up to 100%\n",
    "    - Primary-key\n",
    "        - (Databases only) value must be unique per column\n",
    "        - Example: A database table can’t have two rows with the same primary key value. A primary key is an identifier in a database that references a column in which each value is unique.\n",
    "    - Set-membership\n",
    "        - (Databases only) values for a column must come from a set of discrete values \n",
    "        - Example: Value for a column must be set to Yes, No, or Not Applicable\n",
    "    - Foreign-key\n",
    "        - (Databases only) values for a column must be unique values coming from a column in another table\n",
    "        - Example: In a U.S. taxpayer database, the State column must be a valid state or territory with the set of acceptable values defined in a separate States table\n",
    "    - Accuracy\n",
    "        - The degree to which the data conforms to the actual entity being measured or described\n",
    "        - The degree of conformity of a measure to a standard or true value\n",
    "        - Example: If values for zip codes are validated by street location, the accuracy of the data goes up.\n",
    "    - Completeness\n",
    "        - The degree to which the data contains all desired components or measures\n",
    "        - The degree to which all required measures are known\n",
    "        - Example: If data for personal profiles required hair and eye color, and both are collected, the data is complete.\n",
    "    - Consistency\n",
    "        - The degree to which the data is repeatable from different points of entry or collection\n",
    "        - The degree to which a set of measures is equivalent across systems\n",
    "        - Example: If a customer has the same address in the sales and repair databases, the data is consistent.\n",
    "    - Validity\n",
    "        - The concept of using data integrity principles to ensure measures conform to defined business rules or constraints\n",
    "- It's important to check that the data you use aligns with the business objective\n",
    "- Well-aligned objectives and data\n",
    "    - You can gain powerful insights and make accurate conclusions when data is well-aligned to business objectives\n",
    "    - As a data analyst, alignment is something you will need to judge\n",
    "    - Good alignment means that the data is relevant and can help you solve a business problem or determine a course of action to achieve a given business objective\n",
    "- Clean data + alignment to business objective = accurate conclusions\n",
    "- Alignment to business objective + additional data cleaning = accurate conclusions\n",
    "- Alignment to business objective + newly discovered variables + constraints = accurate conclusions\n",
    "- VLOOKUP\n",
    "    - Spreadsheet function that searches for a certain value in a column to return a related piece of information\n",
    "- DATEDIF\n",
    "    - Calculate the difference between the dates\n",
    "    - Calculate the number of days between two dates\n",
    "- When there is clean data and good alignment, you can get accurate insights and make conclusions the data supports\n",
    "- If there is good alignment but the data needs to be cleaned, clean the data before you perform your analysis\n",
    "- If the data only partially aligns with an objective, think about how you could modify the objective, or use data constraints to make sure that the subset of data better aligns with the business objective\n",
    "\n",
    "#### Overcoming the challenges of insufficient data\n",
    "- Challenges are bound to come up, but once you know your business objective you'll be able to recognize whether you have enough data. And if you don't, you'll be able to deal with it before you start your analysis\n",
    "- Types of insufficient data\n",
    "    - Data from only one source\n",
    "    - Data that keeps updating\n",
    "    - Outdated data\n",
    "    - Geographically-limited data\n",
    "- Ways to address insufficient data\n",
    "    - Identify trends with the available data\n",
    "    - Wait for more data if time allows\n",
    "    - Talk with stakeholders to adjust your objective\n",
    "    - Look for a new dataset\n",
    "- What to do when you find an issue with your data\n",
    "    - No data\n",
    "        - Solution 1\n",
    "            - Gather the data on a small scale to perform a preliminary analysis and then request additional time to complete the analysis after you have collected more data. \n",
    "            - Example: If you are surveying employees about what they think about a new performance and bonus plan, use a sample for a preliminary analysis. Then, ask for another 3 weeks to collect the data from all employees.\n",
    "        - Solution 2\n",
    "            - If there isn’t time to collect data, perform the analysis using proxy data from other datasets. This is the most common workaround\n",
    "            - Example: If you are analyzing peak travel times for commuters but don’t have the data for a particular city, use the data from another city with a similar size and demographic. \n",
    "    - Too little data\n",
    "        - Solution 1\n",
    "            - Do the analysis using proxy data along with actual data\n",
    "            - Example: If you are analyzing trends for owners of golden retrievers, make your dataset larger by including the data from owners of labradors\n",
    "        - Solution 2\n",
    "            - Adjust your analysis to align with the data you already have\n",
    "            - Example: If you are missing data for 18- to 24-year-olds, do the analysis but note the following limitation in your report: this conclusion applies to adults 25 years and older only\n",
    "    - Wrong data, including data with errors\n",
    "        - Solution 1\n",
    "            - If you have the wrong data because requirements were misunderstood, communicate the requirements again.\n",
    "            - Example: If you need the data for female voters and received the data for male voters, restate your needs.\n",
    "        - Solution 2\n",
    "            - Identify errors in the data and, if possible, correct them at the source by looking for a pattern in the errors\n",
    "            - Example: If your data is in a spreadsheet and there is a conditional statement or boolean causing calculations to be wrong, change the conditional statement instead of just fixing the calculated values\n",
    "        - Solution 3\n",
    "            - If you can’t correct data errors yourself, you can ignore the wrong data and go ahead with the analysis if your sample size is still large enough and ignoring the data won’t cause systematic bias\n",
    "            - Example: If your dataset was translated from a different language and some of the translations don’t make sense, ignore the data with bad translation and go ahead with the analysis of the other data\n",
    "- Decision tree on how to deal with data errors or not enough data\n",
    "![decision tree](https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/nubavN6IS5mm2rzeiFuZgw_1204106238b34cff9a89859772cdfaa1_Screen-Shot-2021-03-05-at-10.36.19-AM.png?expiry=1700352000000&hmac=9EmnpUoPqBTwZOISDCVSiX9LHAnf-9DIzUvFOAtNkrQ)\n",
    "- Population\n",
    "    - All possible data values in a certain dataset\n",
    "    - The entire group that you are interested in for your study. For example, if you are surveying people in your company, the population would be all the employees in your company\n",
    "    - This is the total number you hope to pull your sample from\n",
    "- Sample\n",
    "    - A subset of your population. Just like a food sample, it is called a sample because it is only a taste. So if your company is too large to survey every individual, you can survey a representative sample of your population\n",
    "- Margin of error\n",
    "    - The maximum amount that the sample results are expected to differ from those of the actual population\n",
    "    - Since a sample is used to represent a population, the sample’s results are expected to differ from what the result would have been if you had surveyed the entire population. This difference is called the margin of error. The smaller the margin of error, the closer the results of the sample are to what the result would have been if you had surveyed the entire population. \n",
    "- Confidence level\n",
    "    - The probability that your sample size accurately reflects the greater population\n",
    "    - How confident you are in the survey results. For example, a 95% confidence level means that if you were to run the same survey 100 times, you would get similar results 95 of those 100 times. Confidence level is targeted before you start your study because it will affect how big your margin of error is at the end of your study.\n",
    "    - Having a 99% confidence level is ideal, but most industries hope for at least 90% or 95% percent confidence level\n",
    "- Confidence interval\n",
    "    - The range of possible values that the population’s result would be at the confidence level of the study. This range is the sample result +/- the margin of error.\n",
    "- Statistical significance\n",
    "    - The determination of whether your result could be due to random chance or not. The greater the significance, the less due to chance.\n",
    "- Sample size\n",
    "    - A part of a population that is representative of the population\n",
    "    - Helps ensure the degree to which you can be confident that your conclusions accurately represent the population\n",
    "    - Cost effective and takes less time\n",
    "- Downside of sample size\n",
    "    - When you only use a small sample of a population, it can lead to uncertainty\n",
    "    - Can't be 100% sure that your statistics are a complete and accurate representation of the population. This leads to sampling bias\n",
    "- Sampling bias\n",
    "    - A sample which isn't representative of the population as a whole\n",
    "- Ramdom sampling\n",
    "    - A way of selecting a sample from a population so that every possible type of the sample has an equal chance of being chosen\n",
    "- Companies usually create sample sizes before data analysis so analysts know that the resulting dataset is representative of a population.\n",
    "- Things to remember when determining the size of your sample\n",
    "    - Don’t use a sample size less than 30. It has been statistically proven that 30 is the smallest sample size where an average result of a sample starts to represent the average result of a population.\n",
    "    - The confidence level most commonly used is 95%, but 90% can work in some cases. \n",
    "- Increase the sample size to meet specific needs of your project:\n",
    "    - For a higher confidence level, use a larger sample size\n",
    "    - To decrease the margin of error, use a larger sample size\n",
    "    - For greater statistical significance, use a larger sample size\n",
    "- Sample size calculators use statistical formulas to determine a sample size\n",
    "- Why a minimum sample of 30?\n",
    "    - This recommendation is based on the Central Limit Theorem (CLT) in the field of probability and statistics. As sample size increases, the results more closely resemble the normal (bell-shaped) distribution from a large number of samples. A sample of 30 is the smallest sample size for which the CLT is still valid. Researchers who rely on regression analysis – statistical methods to determine the relationships between controlled and dependent variables – also prefer a minimum sample of 30\n",
    "- Sample sizes vary by business problem\n",
    "    - Sample size will vary based on the type of business problem you are trying to solve\n",
    "    - For example, if you live in a city with a population of 200,000 and get 180,000 people to respond to a survey, that is a large sample size. But without actually doing that, what would an acceptable, smaller sample size look like? Would 200 be alright if the people surveyed represented every district in the city? \n",
    "        - Answer:\n",
    "            - It depends on the stakes. \n",
    "            - A sample size of 200 might be large enough if your business problem is to find out how residents felt about the new library\n",
    "            - A sample size of 200 might not be large enough if your business problem is to determine how residents would vote to fund the library\n",
    "            - You could probably accept a larger margin of error surveying how residents feel about the new library versus surveying residents about how they would vote to fund it. For that reason, you would most likely use a larger sample size for the voter survey\n",
    "- Larger sample sizes have a higher cost\n",
    "    - You also have to weigh the cost against the benefits of more accurate results with a larger sample size. Someone who is trying to understand consumer preferences for a new line of products wouldn’t need as large a sample size as someone who is trying to understand the effects of a new drug. For drug safety, the benefits outweigh the cost of using a larger sample size. But for consumer preferences, a smaller sample size at a lower cost could provide good enough results. \n",
    "- Knowing the basics is helpful\n",
    "    - Knowing the basics will help you make the right choices when it comes to sample size. You can always raise concerns if you come across a sample size that is too small. A sample size calculator is also a great tool for this. \n",
    "    - Sample size calculators let you enter a desired confidence level and margin of error for a given population size. They then calculate the sample size needed to statistically achieve those results\n",
    "- Complete the following tasks before analyzing data:\n",
    "    - Determine data integrity by assessing the overall accuracy, consistency, and completeness of the data\n",
    "    - Connect objectives to data by understanding how your business objectives can be served by an investigation into the data\n",
    "    - Know when to stop collecting data\n",
    "- Pre-cleaning activities\n",
    "    - Data analysts perform pre-cleaning activities to complete the steps above\n",
    "    - Pre-cleaning activities help you determine and maintain data integrity\n",
    "    - Pre-cleaning activities are important because they increase the efficiency and success of your data analysis tasks\n",
    "- Problems that might occur if you don't follow pre-cleaning steps\n",
    "    - You may find that you are working with inaccurate or missing data, which can cause misleading results in your analysis\n",
    "    - If you don’t connect objectives with the data, your analysis may not be relevant to the stakeholders\n",
    "    - Finally, not understanding when to stop collecting data can lead to unnecessary delays in completing tasks\n",
    "- If an analyst does not have the data needed to meet a business objective, they should gather related data on a small scale and request additional time. Then, they can find more complete data or perform the analysis by finding and using proxy data from other datasets.\n",
    "\n",
    "#### Testing your data\n",
    "- Statistical power\n",
    "    - Is the probability of getting meaningful results from a test\n",
    "    - The larger the sample size, the greater the chance you'll have statistically significant results with your test\n",
    "    - Usually shown as a value out of one\n",
    "        - Example: If your statistical power is 0.6, that's the same thing as saying 60%\n",
    "        - Meaning: There's 60% chance of you getting statistically significant result\n",
    "    - Can be calculated and reported for a completed experiment to comment on the confidence one might have in the conclusions drawn from the results of the study. It can also be used as a tool to estimate the number of observations or sample size required in order to detect an effect in an experiment\n",
    "- Hypothesis testing\n",
    "    - A way to see if a survey or experiment has meaningful results\n",
    "- Statistically significant\n",
    "    - Is a term that is used in statistics\n",
    "    - If a test is statistically significant, it means the results of the test are real and not an error caused by random chance\n",
    "    - Usually, you need a statistical power of at least 0.8 or 80% to consider your results statistically significant\n",
    "- What to do when there is no data\n",
    "    - Proxy data examples:\n",
    "        - Scenario 1\n",
    "            - Business scenario: A new car model was just launched a few days ago and the auto dealership can’t wait until the end of the month for sales data to come in. They want sales projections now.\n",
    "            - Proxy: The analyst proxies the number of clicks to the car specifications on the dealership’s website as an estimate of potential sales at the dealership.\n",
    "        - Scenario 2\n",
    "            - Business scenario: A brand new plant-based meat product was only recently stocked in grocery stores and the supplier needs to estimate the demand over the next four years. \n",
    "            - Proxy: The analyst proxies the sales data for a turkey substitute made out of tofu that has been on the market for several years.\n",
    "        - Scenario 3\n",
    "            - Business scenario: The Chamber of Commerce wants to know how a tourism campaign is going to impact travel to their city, but the results from the campaign aren’t publicly available yet.\n",
    "            - Proxy: The analyst proxies the historical data for airline bookings to the city one to three months after a similar campaign was run six months earlier.\n",
    "- Confidence level and margin of error don't have to add up to 100%. They're independent of each other.\n",
    "- Sample size calculator\n",
    "    - Tells you how many people you need to interview (or things you need to test) to get results that represent the target population\n",
    "- Estimated response rate\n",
    "    - If you are running a survey of individuals, this is the percentage of people you expect will complete your survey out of those who received the survey\n",
    "    - If you need a sample size of 100 individuals and your estimated response rate is 10%, you will need to send your survey to 1,000 individuals to get the 100 responses you need for your analysis\n",
    "- The calculated sample size is the minimum number to achieve what you input for confidence level and margin of error\n",
    "- In order for an experiment to be statistically significant, the results should be real and not caused by random chance\n",
    "- In order to have a high confidence level in a customer survey, the sample size should accurately reflect the entire population.\n",
    "\n",
    "#### Consider the margin of error\n",
    "- Based on the sample size, the resulting margin of error will tell us how different the results might be compared to the results if we had surveyed the entire population\n",
    "- Margin of error helps you understand how reliable the data from your hypothesis testing is\n",
    "- The closer to zero the margin of error, the closer your results from your sample would match results from the overall population\n",
    "- Example: \n",
    "    - Let's say you completed a nationwide survey using a sample of the population. You asked people who work five-day workweeks whether they like the idea of a four-day workweek. So your survey tells you that 60% prefer a four-day workweek. The margin of error was 10%, which tells us that between 50 and 70% like the idea. So if we were to survey all five-day workers nationwide, between 50 and 70% would agree with our results.\n",
    "    - Keep in mind that our range is between 50 and 70%. That's because the margin of error is counted in both directions from the survey results of 60%. If you set up a 95% confidence level for your survey, there'll be a 95% chance that the entire population's responses will fall between 50 and 70% saying, yes, they want a four-day workweek.\n",
    "    - Since your margin of error overlaps with that 50% mark, you can't say for sure that the public likes the idea of a four-day workweek. In that case, you'd have to say your survey was inconclusive.\n",
    "- If you've already been given the sample size, you can calculate the margin of error yourself. Then you can decide yourself how much of a chance your results have of being statistically significant based on your margin of error. In general, the more people you include in your survey, the more likely your sample is representative of the entire population.\n",
    "- Decreasing the confidence level would also have the same effect, but that would also make it less likely that your survey is accurate.\n",
    "- To calculate margin of error you need:\n",
    "    - Population size\n",
    "    - Sample size\n",
    "    - Confidence level\n",
    "- Search \"margin of error calculator\" online\n",
    "- A/B testing (or split testing) \n",
    "    - Tests two variations of the same web page to determine which page is more successful in attracting user traffic and generating revenue\n",
    "- Conversion rate\n",
    "    - User traffic that gets monetized is known as the conversion rate\n",
    "- Margin of error helps you understand and interpret survey or test results in real-life\n",
    "- Calculating the margin of error is particularly helpful when you are given the data to analyze\n",
    "- After using a calculator to calculate the margin of error, you will know how much the sample results might differ from the results of the entire population\n",
    "\n",
    "##### Datasets\n",
    "- CSV: [Credit card customers](https://www.kaggle.com/datasets/sakshigoyal7/credit-card-customers)\n",
    "- JSON: [Trending YouTube videos](https://www.kaggle.com/datasets/datasnaek/youtube-new)\n",
    "- SQLite: [U.S. wildfire data](https://www.kaggle.com/datasets/rtatman/188-million-us-wildfires)\n",
    "- BigQuery: [Google Analytics 360](https://www.kaggle.com/datasets/bigquery/google-analytics-sample)\n",
    "\n",
    "##### Further reading\n",
    "- [Central Limit Theorem (CLT)](https://www.investopedia.com/terms/c/central_limit_theorem.asp)\n",
    "- [Sample Size Formula](https://www.statisticssolutions.com/dissertation-resources/sample-size-calculation-and-sample-size-justification/sample-size-formula/)\n",
    "- [Determine the Best Sample Size](https://www.coursera.org/learn/process-data/lecture/mSj5A/determine-the-best-sample-size)\n",
    "- [Sample Size Calculator](https://www.coursera.org/learn/process-data/supplement/ZqcDw/sample-size-calculator)\n",
    "- [Survey Monkey Sample Size Calculator](https://www.surveymonkey.com/mp/sample-size-calculator/)\n",
    "- [Raosoft Sample Size Calculator](http://www.raosoft.com/samplesize.html)\n",
    "- [A Gentle Introduction to Statistical Power and Power Analysis in Python](https://machinelearningmastery.com/statistical-power-and-power-analysis-in-python/)\n",
    "- [Is There a Difference Between Open Data and Public Data?](https://medium.com/thinkdata/is-there-a-difference-between-open-data-and-public-data-2b8d5608b2f1)\n",
    "- [4 Examples of Business Analytics In Action](https://online.hbs.edu/blog/post/business-analytics-examples)\n",
    "- [To Get To The Root Of A Hard Problem, Just Ask “Why” Five Times](https://www.fastcompany.com/1669738/to-get-to-the-root-of-a-hard-problem-just-ask-why-five-times)\n",
    "\n",
    "#### Glossary\n",
    "https://docs.google.com/document/d/1iPgiXhYGya72hWKw3eQpf68PV7Ta3Ud317ad-xX_n1E/template/preview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55784813-2c0a-4161-bb8f-1dc9997a2886",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa3e09b-aa4d-4fe9-afa2-b97fb94bfa63",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Module 2: Sparkling-clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2983222d-a586-44ad-88ae-c55d2bd61e81",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Learning log\n",
    "\n",
    "#### Data cleaning is a must\n",
    "- Yearly cost of poor-quality data in the US alone is $3.1 trillion USD according to IBM\n",
    "- Human error is the #1 cause of poor quality data\n",
    "- Dirty data can be the result of\n",
    "    - Typing a piece of data incorrectly\n",
    "    - Inconsistent formatting\n",
    "    - Blank fields\n",
    "    - Duplicate data\n",
    "- Dirty data\n",
    "    - Data that is incomplete, incorrect, or irrelevant to the problem you're trying to solve\n",
    "    - When you work with dirty data, you can't be sure that your results are correct. In fact, you can pretty much bet they won't be\n",
    "    - It can't be used in a meaningful way\n",
    "- Clean data\n",
    "    - Data that is complete, correct, and relevant to the problem that you're trying to solve\n",
    "    - It's something that you should do and do properly because otherwise it can cause serious problems\n",
    "    - This allows you to understand and analyze information and identify important patterns, connect related information, and draw useful conclusions\n",
    "- Data engineers\n",
    "    - Transform data into a useful format for analysis and give it a reliable infrastructure\n",
    "    - They develop, maintain, and test databases, data processors, and related systems\n",
    "- Data warehousing specialists\n",
    "    - Develop processes and procedures to effectively store and organize data\n",
    "    - They make sure that data is available, secure, and backed up to prevent loss\n",
    "- It's important to remember that no dataset is perfect. It's always a good idea to examine and clean data before beginning analysis\n",
    "- Null\n",
    "    - An indication that a value does not exist in a dataset\n",
    "    - It's not the same as zero\n",
    "    - To do your analysis, you would need to first clean this data. Step 1 is to decide what to do with nulls. Either filter them out and communicate that you now have smaller sample size, or keep them in and learn from the fact that customers did not provide responses\n",
    "        - Reasons why this could happen:\n",
    "            - Maybe your survey questions weren't written as well as they could be\n",
    "            - Maybe they were confusing or biased\n",
    "- Types of dirty data\n",
    "    - Duplicate data\n",
    "        - Any data record that shows up more than once\n",
    "        - Cause: Manual data entry, batch data imports, or data migration\n",
    "        - Effect: Skewed metrics or analyses, inflated or inaccurate counts or predictions, or confusion during data retrieval\n",
    "    - Outdated data\n",
    "        - Any data that is old which should be replaced with newer and more accurate information\n",
    "        - Cause: People changing roles or companies, or software and systems becoming obsolete\n",
    "        - Effect: Inaccurate insights, decision-making, and analytics\n",
    "    - Incomplete data\n",
    "        - Any data that is missing important fields\n",
    "        - Cause: Improper data collection or incorrect data entry\n",
    "        - Effect: Decreased productivity, inaccurate insights, or inability to complete essential services\n",
    "    - Incorrect/inaccurate data\n",
    "        - Any data that is complete but inaccurate\n",
    "        - Cause: Human error inserted during data input, fake information, or mock data\n",
    "        - Effect: Inaccurate insights or decision-making based on bad information resulting in revenue loss\n",
    "    - Inconsistent data\n",
    "        - Any data that uses different formats to represent the same thing\n",
    "        - Cause: Data stored incorrectly or errors inserted during data transfer\n",
    "        - Effect: Contradictory data points leading to confusion or inability to classify or segment customers\n",
    "- Field\n",
    "    - A single piece of information from a row or column of a spreadsheet\n",
    "- Field length\n",
    "    - A tool for determining how many characters can be keyed into a field\n",
    "- Data validation\n",
    "    - A tool for checking the accuracy and quality of data before adding or importing it\n",
    "    \n",
    "#### Begin cleaning data\n",
    "- It's always a good practice to make a copy of the dataset\n",
    "- Removing unwanted data\n",
    "    - Remove duplicates\n",
    "    - Remove irrelevant data  or data that isn't relevant to the problem you're trying to solve\n",
    "    - Remove extra spaces and blanks\n",
    "    - Fix misspellings\n",
    "    - Inconsistent capitalization\n",
    "    - Incorrect punctuation and other typos\n",
    "    - Removing formatting\n",
    "- Merger\n",
    "    - An agreement that unites two organizations into a single new one\n",
    "- Data merging\n",
    "    - The process of combining two or more datasets into a single dataset\n",
    "- Compatibility\n",
    "    - How well two or more datasets are able to work together\n",
    "- Questions\n",
    "    - Do I have all the data I need?\n",
    "    - Does the data I need exists within these datasets?\n",
    "    - Do the datasets need to be cleaned, or are they ready for me to use?\n",
    "    - Are the datasets cleaned to the same standard?\n",
    "- Common data-cleaning pitfalls\n",
    "    - Not checking for spelling errors\n",
    "        - Misspellings can be as simple as typing or input errors. Most of the time the wrong spelling or common grammatical errors can be detected, but it gets harder with things like names or addresses\n",
    "    - Forgetting to document errors\n",
    "        - Documenting your errors can be a big time saver, as it helps you avoid those errors in the future by showing you how you resolved them\n",
    "    - Not checking for misfielded values\n",
    "        - A misfielded value happens when the values are entered into the wrong field. These values might still be formatted correctly, which makes them harder to catch if you aren’t careful\n",
    "    - Overlooking missing values\n",
    "        - Missing values in your dataset can create errors and give you inaccurate conclusions\n",
    "    - Looking at a subset of data and not the whole picture\n",
    "        - It is important to think about all of the relevant data when you are cleaning. This helps make sure you understand the whole story the data is telling, and that you are paying attention to all possible errors\n",
    "    - Losing track of business objective\n",
    "        - When you are cleaning data, you might make new and interesting discoveries about your dataset-- but you don’t want those discoveries to distract you from the task at hand\n",
    "    - Not fixing the source of the error\n",
    "        - Fixing the error itself is important. But if that error is actually part of a bigger problem, you need to find the source of the issue. Otherwise, you will have to keep fixing that same error over and over again\n",
    "    - Not analyzing the system prior to data cleaning\n",
    "        - If we want to clean our data and avoid future errors, we need to understand the root cause of your dirty data\n",
    "    - Not backing up your data prior to data cleansing\n",
    "        - It is always good to be proactive and create your data backup before you start your data clean-up. If your program crashes, or if your changes cause a problem in your dataset, you can always go back to the saved version and restore it. The simple procedure of backing up your data can save you hours of work-- and most importantly, a headache.\n",
    "    - Not accounting for data cleansing in your deadlines/process\n",
    "        - All good things take time, and that includes data cleaning. It is important to keep that in mind when going through your process and looking at your deadlines. When you set aside time for data cleaning, it helps you get a more accurate estimate for ETAs for stakeholders, and can help you know when to request an adjusted ETA\n",
    "\n",
    "#### Cleaning data in spreadsheets\n",
    "- Conditional formatting\n",
    "    - A spreadsheet tool that changes how cells appear when values meet specific conditions\n",
    "- Remove duplicates\n",
    "    - A tool that automatically searches for and eliminates duplicate entries from a spreadsheet\n",
    "- Text string\n",
    "    - A group of characters within a cell, most often composed of letters\n",
    "- Split\n",
    "    - A tool that divides a text string around the specified character and puts each fragment into a new and separate cell\n",
    "- Concatenate\n",
    "    - A function that joins multiple text strings into a single string\n",
    "- Syntax\n",
    "    - A predetermined structure that includes all required information and its proper placement\n",
    "- What can be automated?\n",
    "    - Communicating with your team and stakeholders\n",
    "        - No\n",
    "        - Communication is key to understanding the needs of your team and stakeholders as you complete the tasks you are working on. There is no replacement for person-to-person communications. \n",
    "    - Presenting your findings\n",
    "        - No\n",
    "        - Presenting your data is a big part of your job as a data analyst. Making data accessible and understandable to stakeholders and creating data visualizations can’t be automated for the same reasons that communications can’t be automated.\n",
    "    - Preparing and cleaning data\n",
    "        - Partially\n",
    "        - Some tasks in data preparation and cleaning can be automated by setting up specific processes, like using a programming script to automatically detect missing values.\n",
    "    - Data exploration\n",
    "        - Partially\n",
    "        - Sometimes the best way to understand data is to see it. Luckily, there are plenty of tools available that can help automate the process of visualizing data. These tools can speed up the process of visualizing and understanding the data, but the exploration itself still needs to be done by a data analyst.\n",
    "    - Modeling the data\n",
    "        - Yes\n",
    "        - Data modeling is a difficult process that involves lots of different factors; luckily there are tools that can completely automate the different stages.\n",
    "- More about automating data cleaning\n",
    "    - One of the most important ways you can streamline your data cleaning is to clean data where it lives. This will benefit your whole team, and it also means you don’t have to repeat the process over and over.\n",
    "- Pivot table\n",
    "    - A data summarization tool that is used in data processing.\n",
    "    - Pivot tables sort, reorganize, group, count, total or average data stored in the database.\n",
    "    - In data cleaning, pivot tables are used to give you a quick, clutter-free view of your data.\n",
    "    - You can choose to look at the specific parts of the data set that you need to get a visual in the form of a pivot table.\n",
    "- VLOOKUP\n",
    "    - Vertical Lookup\n",
    "    - A function that searches for a certain value in a column to return a corresponding piece of information\n",
    "    - VLOOKUP searches for the value in the first argument in the leftmost column of the specified location\n",
    "- Plotting\n",
    "    - When you plot data, you put it in a graph chart, table, or other visual to help you quickly find what it looks like\n",
    "    - Plotting is very useful when trying to identify any skewed data or outliers\n",
    "- Data mapping\n",
    "    - The process of matching fields from one database to another.\n",
    "\n",
    "\n",
    "##### Further reading\n",
    "- Data cleaning\n",
    "    - [Top ten ways to clean your data](https://support.microsoft.com/en-us/office/top-ten-ways-to-clean-your-data-2844b620-677c-47a7-ac3e-c2e157d1db19)\n",
    "    - [10 Google Workspace tips to clean up data](https://support.google.com/a/users/answer/9604139?hl=en#zippy=)\n",
    "- Automation\n",
    "    - [Automating Scientific Data Analysis](https://towardsdatascience.com/automating-scientific-data-analysis-part-1-c9979cd0817e)\n",
    "    - [Automating Big-Data Analysis](https://news.mit.edu/2016/automating-big-data-analysis-1021)\n",
    "    - [10 of the Best Options for Workflow Automation Software](https://technologyadvice.com/blog/information-technology/top-10-workflow-automation-software/)\n",
    "\n",
    "#### Glossary\n",
    "https://docs.google.com/document/d/1bdwobtiQ4NJGkaMghHPlj4z6V-knT6B-o6GGI4xsiDM/template/preview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104bb1cc-7b39-4742-a596-1a38844cfaa4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d5794b-09d4-41da-9608-88cd50250205",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Module 3: Cleaning data with SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7de37c7-860a-4745-bedf-eb8136e2e9d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Learning log\n",
    "\n",
    "#### Using SQL to clean data\n",
    "- SQL is the primary way data analysts extract data from databases\n",
    "- Spreadsheets functions and formulas or SQL queries?\n",
    "    - First, they have to think about where the data lives\n",
    "        - If it is stored in a database, then SQL is the best tool for the job\n",
    "        - If it is stored in a spreadsheet, then they will have to perform their analysis in that spreadsheet\n",
    "- Features of Spreadsheets\n",
    "    - Smaller data sets\n",
    "    - Enter data manually\n",
    "    - Create graphs and visualizations in the same program\n",
    "    - Built-in spell check and other useful functions\n",
    "    - Best when working solo on a project\n",
    "- Features of SQL Databases \n",
    "    - Larger datasets\n",
    "    - Access tables across a database\n",
    "    - Prepare data for further analysis in another software\n",
    "    - Fast and powerful functionality\n",
    "    - Great for collaborative work and tracking queries run by all users\n",
    "\n",
    "#### Learn basic SQL queries\n",
    "\n",
    "#### Transforming data\n",
    "\n",
    "##### Further reading\n",
    "- SQL dialects and their uses\n",
    "    - [What Is a SQL Dialect, and Which one Should You Learn?](https://learnsql.com/blog/what-sql-dialect-to-learn/)\n",
    "    - [Difference Between SQL Vs MySQL Vs SQL Server](https://www.softwaretestinghelp.com/sql-vs-mysql-vs-sql-server/)\n",
    "    - [SQL Server, PostgreSQL, MySQL... what's the difference? Where do I start?](https://www.datacamp.com/blog/sql-server-postgresql-mysql-whats-the-difference-where-do-i-start)\n",
    "    - [SQLite Window Functions](https://sqlite.org/windowfunctions.html)\n",
    "    - [What Is SQL](https://www.sqltutorial.org/what-is-sql/)\n",
    "    - [Datacamp Data Engineering](https://www.datacamp.com/learn/popular/data-engineering)\n",
    "- \n",
    "    \n",
    "#### Glossary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91b0f6f-aade-45b5-a740-f774622e6246",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86fb882-8ed3-40f5-8932-425006043713",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Module 4: Verify and report on your cleaning results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57b30bf-778c-4b9e-a349-3199490cf9ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Learning log\n",
    "\n",
    "#### Manually cleaning data\n",
    "\n",
    "#### Documenting results and the cleaning process\n",
    "\n",
    "##### Further reading\n",
    "\n",
    "#### Glossary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e03da72-0d46-43b4-abd1-85f3cb2ff010",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bce25b-e501-40d6-9a3c-7368c53c5afc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Module 5: Adding data to your resume"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
